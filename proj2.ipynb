{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TABLES AND COMPARISON ARE AT THE END**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Madison, Wisconsin is about 1300 miles from Waterville, Maine.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Madison', ',', 'Wisconsin', 'is', 'about', '1300', 'miles', 'from', 'Waterville', ',', 'Maine', '.']\n"
     ]
    }
   ],
   "source": [
    "token_texts = [token.text for token in doc]\n",
    "\n",
    "print(token_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Madison', ',', 'Wisconsin', 'be', 'about', '1300', 'mile', 'from', 'Waterville', ',', 'Maine', '.']\n"
     ]
    }
   ],
   "source": [
    "token_lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "print(token_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROPN', 'PUNCT', 'PROPN', 'AUX', 'ADV', 'NUM', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "token_coarse_tags = [token.pos_ for token in doc]\n",
    "\n",
    "print(token_coarse_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Madison', 'Wisconsin', 'about 1300 miles', 'Waterville', 'Maine']\n",
      "['PERSON', 'GPE', 'QUANTITY', 'GPE', 'GPE']\n"
     ]
    }
   ],
   "source": [
    "entity_texts = [ent.text for ent in doc.ents]\n",
    "entity_types = [ent.label_ for ent in doc.ents]\n",
    "\n",
    "print(entity_texts)\n",
    "\n",
    "print(entity_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FROM SPACY**\n",
    "\n",
    " Num| Token | Lemma | Part of speech | Named Entities |                                         \n",
    "|---| ------- | ----- | -------------------------- | ---------| \n",
    "| 1 | Madison |   Madison     |   PROPN         |   Person    |\n",
    "| 2 |  ,      |   ,     |    PUNCT              |             |\n",
    "| 3 | Wisconsin      |   Wisconsin    |  PROPN  |   GPE       |\n",
    "| 4 |  is     |  be     |    AUX                |             |\n",
    "| 5 |  about  |  about     |    ADV             |   Quantity  |\n",
    "| 6 |   1300  |   1300    |      NUM            |   Quantity  |\n",
    "| 7 |  miles  |  mile     |      NOUN           |   Quantity  |\n",
    "| 8 |  from   | from      |        ADP.         |             |\n",
    "| 9 |  Waterville |   Waterville    |  PROPN    |             |\n",
    "| 10 |  ,     | ,      |        PUNCT           |             |\n",
    "| 11 |   Maine |  Maine     |  PROPN            |             |\n",
    "| 12 |   .    |   .    |      PUNCT             |             |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FROM CHATGPT**\n",
    "\n",
    "| Line | Token | Lemma | POS | Named Entity |\n",
    "|------|-------|-------|-----|--------------|\n",
    "| 1 | Madison | Madison | PROPN | GPE |\n",
    "| 2 | , | , | PUNCT | - |\n",
    "| 3 | Wisconsin | Wisconsin | PROPN | GPE |\n",
    "| 4 | is | be | AUX | - |\n",
    "| 5 | about | about | ADV | - |\n",
    "| 6 | 1300 | 1300 | NUM | - |\n",
    "| 7 | miles | mile | NOUN | QUANTITY |\n",
    "| 8 | from | from | ADP | - |\n",
    "| 9 | Waterville | Waterville | PROPN | GPE |\n",
    "| 10 | , | , | PUNCT | - |\n",
    "| 11 | Maine | Maine | PROPN | GPE |\n",
    "| 12 | . | . | PUNCT | - |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPARISON**\n",
    "\n",
    "| Component | Analysis |\n",
    "| --------- | -------- |\n",
    "| Token | Both ChatGPT and spaCy seem to be able to successfully distinguish the tokens in a given text, including punctuations. They are both correct.|\n",
    "| Lemma | Both ChatGPT and spaCy seem to be able to successfully extrapolate the lemma of tokens where they exist. They are both correct. |\n",
    "| POS | Once again, both ChatGPT and spaCy are able to successfully and correctly determine the part of speech that a token belongs to.|\n",
    "| Named Entity | While both ChatGPT and spaCy were able to successfully undertake Named Entity Recognition (NER) of the tokens, they were not always correct. spaCy incorrectly recognized \"Madison\" as a Person whereas ChatGPT was able to recognize it as a GPE. On the other hand, spaCy correctly recognized all the tokens in the phrase \"about 1300 miles\" as a quantity, whereas ChatGPT only recognized \"miles\" as a Quantity.|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
